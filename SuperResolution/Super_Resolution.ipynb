{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiZihHVPtKm"
      },
      "source": [
        "## Part 1: External libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwgqA7viPtKr",
        "outputId": "baf91ae4-5a0f-4a56-8a8f-32e3bb136af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.11.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.26)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Collecting tensorflow-gpu==2.12.0\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "# Set up for Colab: tf2.1 and PyDrive to download the dataset\n",
        "# installing tensorflow 2.1\n",
        "!pip install --quiet tensorflow-gpu==2.12.0\n",
        "!pip install tensorflow==2.12.0\n",
        "\n",
        "# After this, restart the runtime to avoid authentication issues\n",
        "!pip install -q -U PyDrive\n",
        "!pip install tensorflow-gpu==2.12.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lX5hTM46PtLM"
      },
      "outputs": [],
      "source": [
        "import os                       # pkg to read filepaths from the dataset folder\n",
        "import tensorflow as tf         # tensorflow\n",
        "import tensorflow.keras as K    # keras API\n",
        "import numpy as np              # numpy to work with tensors (with tf)\n",
        "import matplotlib.pyplot as plt # function to show images\n",
        "%matplotlib inline\n",
        "import cv2                      # pkg to load image as np.array\n",
        "\n",
        "# vgg net for perceptual loss\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "# Import PyDrive2 and associated libraries.\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Mounting Google Drive and Importing External Libraries"
      ],
      "metadata": {
        "id": "QSuOUf4ns7fb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7YLhnEPPtK3",
        "outputId": "ebc8bf88-cfb7-412b-e8cf-51c96df582e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: Using Google Colab\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# Authenticate and create the PyDrive2 client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#avishai adding\n",
        "# Mount Google Drive if using Colab\n",
        "try:\n",
        "    from google.colab import drive as colab_drive\n",
        "    colab_drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: Using Google Colab\")\n",
        "    %tensorflow_version 2.x  # Assuming you want to switch to TensorFlow 2.x\n",
        "except:\n",
        "    print(\"Note: Not using Google Colab\")\n",
        "    COLAB = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDTG5u-ZPtLD",
        "outputId": "72ad3502-7be1-456a-cdd3-c6d7a0bce990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  Linnaeus_5_bigger.zip  sample_data\n",
            "test_128  train_256\n"
          ]
        }
      ],
      "source": [
        "# Specifying the file ID\n",
        "file_id = '19Q0BLy0jyxjZsa-4V_oM9Cw2QTIIlGeZ'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "\n",
        "# Download the file to the Colab environment\n",
        "downloaded.GetContentFile('Linnaeus_5_bigger.zip')\n",
        "\n",
        "# Check the files in the current directory to confirm the zip file is downloaded\n",
        "!ls\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip -q Linnaeus_5_bigger.zip\n",
        "\n",
        "# List contents of the directory to confirm the extraction\n",
        "!ls Linnaeus_5_bigger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHEXIKQ_PtLT"
      },
      "source": [
        "## Part 3: Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eXiI4MI7PtLU"
      },
      "outputs": [],
      "source": [
        "# defining the hyperparamters\n",
        "input_size_test = 128 # 128x128x3 images (training_set)\n",
        "input_size_train = 256 # 128x128x3 images (training_set)\n",
        "batch_size= 16\n",
        "num_epochs=20\n",
        "noise_param=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH-clzZEPtLY",
        "outputId": "ac6071c6-93fb-4942-8aa1-94e2c4184d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 4s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,735,488\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Perceptual loss function\n",
        "\n",
        "# load pre-trained (imagenet) vgg network, excluding fully-connected layer on the top\n",
        "vgg = VGG19(include_top=False, weights='imagenet', input_shape=(None,None,3))\n",
        "vgg_layer = K.Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "# make the net not trainable\n",
        "for l in vgg_layer.layers: l.trainable=False\n",
        "\n",
        "print(vgg_layer.summary())\n",
        "\n",
        "def perceptual_loss(y_true,y_pred):\n",
        "    '''This function computes the perceptual loss using an already trained VGG layer'''\n",
        "    y_t=vgg_layer(y_true)\n",
        "    y_p=vgg_layer(y_pred)\n",
        "    loss=K.losses.mean_squared_error(y_t,y_p)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ebw4SZ_aPtLj"
      },
      "outputs": [],
      "source": [
        "# defining other metrics:\n",
        "def psnr(y_true,y_pred):\n",
        "    return tf.image.psnr(y_true,y_pred,1.0)\n",
        "def ssim(y_true,y_pred):\n",
        "    return tf.image.ssim(y_true,y_pred,1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ht3syGLbPtLm"
      },
      "outputs": [],
      "source": [
        "def image_proc_net(training_mode=True):\n",
        "    \"\"\"\n",
        "    Function which creates the model to preprocess images.\n",
        "    2 different types of model with different layers depending\n",
        "    on whether it is in training mode or in testing mode\n",
        "    \"\"\"\n",
        "    inputs = K.layers.Input((None, None, 3))\n",
        "    if training_mode:\n",
        "        # training mode: downsampling, gaussian noise and upsampling\n",
        "        x = K.layers.MaxPool2D(pool_size=(2,2))(inputs)\n",
        "        x = K.layers.GaussianNoise(noise_param)(x)  # Adjusted stddev to be within the valid range\n",
        "        x = K.layers.UpSampling2D((2,2))(x)\n",
        "    else:\n",
        "        # testing mode: just an upsampling\n",
        "        x = K.layers.UpSampling2D((2,2))(inputs)\n",
        "\n",
        "    model = K.models.Model(inputs, x)\n",
        "\n",
        "    for l in model.layers: l.trainable=False\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiating the two models (for train and test)\n",
        "image_proc_train = image_proc_net(training_mode=True)\n",
        "image_proc_test = image_proc_net(training_mode=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G-1LcBGPtLt",
        "outputId": "bd3c8468-8533-47f8-f4d5-de08cac83ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, None, None, 3)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " gaussian_noise (GaussianNoi  (None, None, None, 3)    0         \n",
            " se)                                                             \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, None, None, 3)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#training_mode\n",
        "print(image_proc_train.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWzqnKlcPtLw",
        "outputId": "918a4944-f88c-484e-af34-1d792cb04c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, None, None, 3)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#testing_mode\n",
        "print(image_proc_test.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5N4dDWowPtL1"
      },
      "outputs": [],
      "source": [
        "def image_preprocess(image, training_mode=True):\n",
        "    \"\"\"\n",
        "    Function which preprocess automatically an image\n",
        "    wether it's in training or testing mode\n",
        "\n",
        "    input:\n",
        "      - image: np array (image tensor)\n",
        "      - training_mode: binary flag\n",
        "    \"\"\"\n",
        "    image = np.expand_dims(image,axis=0)\n",
        "    if training_mode:\n",
        "        return tf.squeeze(image_proc_train(image))\n",
        "    else:\n",
        "        return tf.squeeze(image_proc_test(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b51gXYowYuGd"
      },
      "outputs": [],
      "source": [
        "# reading image\n",
        "def read_image(img_path):\n",
        "    \"\"\"\n",
        "    function which loads an image from a path and convert it into np array\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    b,g,r = cv2.split(img)   # cv2 reads BGR instead of canonical RGB\n",
        "    img = cv2.merge([r,g,b]) # Switching it to RGB\n",
        "\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYy4u23MPtL3",
        "outputId": "52c01469-5ad5-4cbf-f09c-06574c36bdf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 2000\n",
            "Training images: 1700\n",
            "Validation images: 300\n",
            "images: \n",
            "train: 1700 val: 300 test: 500\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "all_images = []  # All train image paths\n",
        "\n",
        "# 256x256 in training phase\n",
        "path = 'Linnaeus_5_bigger/train_256'\n",
        "\n",
        "# Check if the path exists\n",
        "if not os.path.exists(path):\n",
        "    print(f\"Path does not exist: {path}\")\n",
        "else:\n",
        "    files = os.listdir(path)\n",
        "    for file in files:\n",
        "        path_file = os.path.join(path, file)\n",
        "        for dirpath, dirnames, filenames in os.walk(path_file):\n",
        "            # Append full path to filenames\n",
        "            filenames = [os.path.join(dirpath, x) for x in filenames]\n",
        "            all_images.extend(filenames)\n",
        "\n",
        "    # Picking only 2000 images\n",
        "    all_images = all_images[:2000]\n",
        "    np.random.shuffle(all_images)  # Random shuffling\n",
        "\n",
        "    # Keep 85% for train and 15% for validation\n",
        "    train_len = int(len(all_images) * 0.85)\n",
        "\n",
        "    train_list = all_images[:train_len]\n",
        "    val_list = all_images[train_len:]\n",
        "\n",
        "    print(f\"Total images: {len(all_images)}\")\n",
        "    print(f\"Training images: {len(train_list)}\")\n",
        "    print(f\"Validation images: {len(val_list)}\")\n",
        "\n",
        "\n",
        "# test\n",
        "# for the test set we opted to take the same dataset\n",
        "# but with images of size 128x128 instead of 256x256\n",
        "\n",
        "test_list = []\n",
        "\n",
        "path = 'Linnaeus_5_bigger/test_128'\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "    path_file = path+'/'+file\n",
        "    for (dirpath, dirnames, filenames) in os.walk(path_file):\n",
        "        filenames = list(map(lambda x:path_file+'/'+x,filenames))\n",
        "        test_list.extend(filenames)\n",
        "\n",
        "np.random.shuffle(test_list) # random shuffling\n",
        "\n",
        "test_list = test_list[:500]\n",
        "\n",
        "print('images: ')\n",
        "print('train:', len(train_list), 'val:', len(val_list), 'test:', len(test_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sjaWDNI4PtL5"
      },
      "outputs": [],
      "source": [
        "# defining train, validation and test generator\n",
        "\n",
        "def train_generator():\n",
        "    global batch_size\n",
        "    while True:\n",
        "        for start in range(0, len(train_list), batch_size):\n",
        "                    x_batch = []\n",
        "                    y_batch = []\n",
        "                    end = min(start + batch_size, len(train_list))\n",
        "                    ids_train_batch = train_list[start:end]\n",
        "                    for i,ids in enumerate(ids_train_batch):\n",
        "                        img_y = read_image(ids)\n",
        "                        img_x = image_preprocess(img_y, training_mode=True)\n",
        "                        x_batch.append(np.array(img_x,np.float32)/255.)\n",
        "                        y_batch.append(np.array(img_y,np.float32)/255.)\n",
        "                    x_batch = np.array(x_batch)\n",
        "                    y_batch = np.array(y_batch)\n",
        "                    yield x_batch,y_batch\n",
        "\n",
        "def valid_generator():\n",
        "    global batch_size\n",
        "    while True:\n",
        "        for start in range(0, len(val_list), batch_size):\n",
        "                    x_batch = []\n",
        "                    y_batch = []\n",
        "                    end = min(start + batch_size, len(val_list))\n",
        "                    ids_val_batch = val_list[start:end]\n",
        "                    for i,ids in enumerate(ids_val_batch):\n",
        "                        img_y = read_image(ids)\n",
        "                        img_x = image_preprocess(img_y, training_mode=True)\n",
        "                        x_batch.append(np.array(img_x,np.float32)/255.)\n",
        "                        y_batch.append(np.array(img_y,np.float32)/255.)\n",
        "                    x_batch = np.array(x_batch)\n",
        "                    y_batch = np.array(y_batch)\n",
        "                    yield x_batch,y_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iwMMcyVgPtL8"
      },
      "outputs": [],
      "source": [
        "# pixel shuffle\n",
        "def pixel_shuffle(scale):\n",
        "    '''\n",
        "    This function implements pixel shuffling.\n",
        "    ATTENTION: the scale should be bigger than 2, otherwise just returns the input.\n",
        "    '''\n",
        "    if scale > 1:\n",
        "        return lambda x: tf.nn.depth_to_space(x, scale)\n",
        "    else:\n",
        "        return lambda x:x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uT11sz5aPtL-"
      },
      "outputs": [],
      "source": [
        "#blocks definition for upscaling/downscaling\n",
        "\n",
        "def add_down_block(x_inp, filters, kernel_size=(3, 3), padding=\"same\", strides=1,r=False):\n",
        "    x = K.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x_inp)\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    x = K.layers.Activation('relu')(x)\n",
        "    x = K.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    if r:\n",
        "        # if r=True then we import an (1X1) Conv2D after input layer\n",
        "        # in order the dimensions of 2 tensors coincide.\n",
        "        x_inp = K.layers.Conv2D(filters,(1,1), padding=padding, strides=strides)(x_inp)\n",
        "    x = K.layers.Add()([x,x_inp])\n",
        "    return x\n",
        "\n",
        "def add_up_block(x_inp, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1, upscale_factor=2):\n",
        "    # Calculate the upsampling factor based on the difference in input sizes\n",
        "    upsampling_factor = skip.shape[1] // x_inp.shape[1]\n",
        "\n",
        "    x = K.layers.UpSampling2D(size=(upsampling_factor, upsampling_factor))(x_inp)\n",
        "\n",
        "    # Adjust the shape of the skip connection tensor\n",
        "    skip = K.layers.Conv2D(filters, kernel_size=(1, 1), padding=\"same\")(skip)\n",
        "\n",
        "    x = K.layers.Concatenate()([x, skip])\n",
        "    x = K.layers.BatchNormalization()(x)\n",
        "    x = K.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    x = K.layers.Activation('relu')(x)\n",
        "    x = K.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    x = K.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def add_bottleneck(x_inp,filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    x = K.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x_inp)\n",
        "    x = K.layers.Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu4XkLrpPtMB",
        "outputId": "fe3678f2-7bf2-475c-95a7-65ed826b51b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  9472        ['input_4[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64  0          ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 64  36928       ['max_pooling2d_1[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 64  36928       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 128, 128, 64  0           ['batch_normalization_2[0][0]',  \n",
            "                                )                                 'max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 64  36928       ['add[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 64  256        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 64  36928       ['activation_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 64  256        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 128, 128, 64  0           ['batch_normalization_4[0][0]',  \n",
            "                                )                                 'add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 64  36928       ['add_1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 64  256        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 64  36928       ['activation_3[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 64  256        ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 128, 128, 64  0           ['batch_normalization_6[0][0]',  \n",
            "                                )                                 'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 12  73856       ['add_2[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 128, 12  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_7[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 128, 12  147584      ['activation_4[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128, 12  512        ['conv2d_8[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 128, 128, 12  8320        ['add_2[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 128, 128, 12  0           ['batch_normalization_8[0][0]',  \n",
            "                                8)                                'conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0          ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 128)  147584      ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 128)  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64, 64, 128)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 128)  147584      ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 128)  512        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 128)  512        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 64, 64, 128)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 64, 64, 128)  147584      ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 128)  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 64, 64, 128)  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 64, 64, 128)  0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 64, 64, 256)  295168      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 64, 64, 256)  33024       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 64, 64, 256)  0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0          ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 32, 32, 256)  590080      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 32, 32, 256)  0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 32, 32, 256)  590080      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 256)  0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 32, 32, 256)  590080      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_22[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 32, 32, 256)  590080      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 32, 32, 256)  590080      ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 32, 32, 512)  1180160     ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 32, 32, 512)  131584      ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 32, 32, 512)  0           ['batch_normalization_28[0][0]', \n",
            "                                                                  'conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0          ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 512)  2359808     ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 16, 16, 512)  0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 16, 16, 512)  2359808     ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 16, 16, 512)  0           ['batch_normalization_32[0][0]', \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 16, 16, 512)  2048       ['add_15[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 16, 16, 1024  4719616     ['activation_17[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 1024  0           ['conv2d_36[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 16, 16, 512)  4719104     ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 512)  0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 512)  0          ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 16, 16, 512)  262656      ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 1024  0           ['up_sampling2d_2[0][0]',        \n",
            "                                )                                 'conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 16, 16, 1024  4096       ['concatenate[0][0]']            \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 512)  4719104     ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 512)  0           ['conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 512)  0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 512)  0          ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 32, 32, 384)  196992      ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 32, 32, 896)  0           ['up_sampling2d_3[0][0]',        \n",
            "                                                                  'conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 32, 32, 896)  3584       ['concatenate_1[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 32, 32, 384)  3096960     ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 32, 32, 384)  0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 32, 32, 384)  1327488     ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 32, 32, 384)  0           ['conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 384)  0          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 64, 64, 256)  65792       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64, 64, 640)  0           ['up_sampling2d_4[0][0]',        \n",
            "                                                                  'conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 64, 64, 640)  2560       ['concatenate_2[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 64, 64, 256)  1474816     ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 64, 64, 256)  0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 64, 64, 256)  0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 25  0          ['activation_25[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 128, 128, 96  12384       ['add_3[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 128, 35  0           ['up_sampling2d_5[0][0]',        \n",
            "                                2)                                'conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 128, 128, 35  1408       ['concatenate_3[0][0]']          \n",
            " ormalization)                  2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 128, 128, 96  304224      ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 128, 128, 96  0           ['conv2d_48[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 128, 128, 96  83040       ['activation_26[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 128, 128, 96  0           ['conv2d_49[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.depth_to_space (TFOpLamb  (None, 256, 256, 24  0          ['activation_27[0][0]']          \n",
            " da)                            )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 256, 256, 88  0           ['tf.nn.depth_to_space[0][0]',   \n",
            "                                )                                 'activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 256, 256, 99  78507       ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 256, 256, 99  0           ['conv2d_50[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 256, 256, 99  88308       ['activation_28[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 256, 256, 99  0           ['conv2d_51[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 256, 256, 3)  300         ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,419,499\n",
            "Trainable params: 45,397,419\n",
            "Non-trainable params: 22,080\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#RUnet architecture layers\n",
        "def RUNet(input_size_train=256, input_size_test=128):\n",
        "    \"\"\"\n",
        "    Implementing with Keras the Robust UNet Architecture as proposed by\n",
        "    Xiaodan Hu, Mohamed A. Naiel, Alexander Wong, Mark Lamm, Paul Fieguth\n",
        "    in \"RUNet: A Robust UNet Architecture for Image Super-Resolution\"\n",
        "    \"\"\"\n",
        "    with tf.device('/device:GPU:0'):  # This line ensures the model is built on the GPU\n",
        "        inputs = K.layers.Input((input_size_train, input_size_train, 3))\n",
        "\n",
        "        down_1 = K.layers.Conv2D(64, (7, 7), padding=\"same\", strides=1)(inputs)\n",
        "        down_1 = K.layers.BatchNormalization()(down_1)\n",
        "        down_1 = K.layers.Activation('relu')(down_1)\n",
        "\n",
        "        down_2 = K.layers.MaxPool2D(pool_size=(2, 2))(down_1)\n",
        "        down_2 = add_down_block(down_2, 64)\n",
        "        down_2 = add_down_block(down_2, 64)\n",
        "        down_2 = add_down_block(down_2, 64)\n",
        "        down_2 = add_down_block(down_2, 128, r=True)\n",
        "\n",
        "        down_3 = K.layers.MaxPool2D(pool_size=(2, 2), strides=2)(down_2)\n",
        "        down_3 = add_down_block(down_3, 128)\n",
        "        down_3 = add_down_block(down_3, 128)\n",
        "        down_3 = add_down_block(down_3, 128)\n",
        "        down_3 = add_down_block(down_3, 256, r=True)\n",
        "\n",
        "        down_4 = K.layers.MaxPool2D(pool_size=(2, 2))(down_3)\n",
        "        down_4 = add_down_block(down_4, 256)\n",
        "        down_4 = add_down_block(down_4, 256)\n",
        "        down_4 = add_down_block(down_4, 256)\n",
        "        down_4 = add_down_block(down_4, 256)\n",
        "        down_4 = add_down_block(down_4, 256)\n",
        "        down_4 = add_down_block(down_4, 512, r=True)\n",
        "\n",
        "        down_5 = K.layers.MaxPool2D(pool_size=(2, 2))(down_4)\n",
        "        down_5 = add_down_block(down_5, 512)\n",
        "        down_5 = add_down_block(down_5, 512)\n",
        "        down_5 = K.layers.BatchNormalization()(down_5)\n",
        "        down_5 = K.layers.Activation('relu')(down_5)\n",
        "\n",
        "        bn_1 = add_bottleneck(down_5, 1024)\n",
        "        bn_2 = add_bottleneck(bn_1, 512)\n",
        "\n",
        "        up_1 = add_up_block(bn_2, down_5, 512, upscale_factor=input_size_train // input_size_test)\n",
        "        up_2 = add_up_block(up_1, down_4, 384, upscale_factor=2)\n",
        "        up_3 = add_up_block(up_2, down_3, 256, upscale_factor=2)\n",
        "        up_4 = add_up_block(up_3, down_2, 96, upscale_factor=2)\n",
        "\n",
        "        up_5 = pixel_shuffle(scale=2)(up_4)\n",
        "        up_5 = K.layers.Concatenate()([up_5, down_1])\n",
        "        up_5 = K.layers.Conv2D(99, (3, 3), padding=\"same\", strides=1)(up_5)\n",
        "        up_5 = K.layers.Activation('relu')(up_5)\n",
        "        up_5 = K.layers.Conv2D(99, (3, 3), padding=\"same\", strides=1)(up_5)\n",
        "        up_5 = K.layers.Activation('relu')(up_5)\n",
        "\n",
        "        outputs = K.layers.Conv2D(3, (1, 1), padding=\"same\")(up_5)\n",
        "        model = K.models.Model(inputs, outputs)\n",
        "        return model\n",
        "\n",
        "model = RUNet()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkNj_WAJPtME",
        "outputId": "6f23b156-c9cd-4669-93de-9f96caf96e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-221c1fa71950>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(generator=train_generator(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "107/107 [==============================] - 4515s 42s/step - loss: 7.1935 - psnr: 11.9597 - ssim: 0.1610 - mean_squared_error: 0.0956 - val_loss: 17.4798 - val_psnr: 11.2495 - val_ssim: 0.1924 - val_mean_squared_error: 0.0843\n",
            "Epoch 2/20\n",
            " 62/107 [================>.............] - ETA: 31:13 - loss: 3.4699 - psnr: 17.1211 - ssim: 0.3087 - mean_squared_error: 0.0206"
          ]
        }
      ],
      "source": [
        "opt=K.optimizers.Adam(learning_rate=0.001) # Adam optimizer\n",
        "model.compile(optimizer=opt,loss=perceptual_loss,metrics=[psnr,ssim,K.losses.mean_squared_error])\n",
        "history = model.fit_generator(generator=train_generator(),\n",
        "                              steps_per_epoch=np.ceil(float(len(train_list)) / float(batch_size)),\n",
        "                              epochs=num_epochs,\n",
        "                              verbose=1,\n",
        "                              validation_data=valid_generator(),\n",
        "                              shuffle=True,\n",
        "                              validation_steps=np.ceil(float(len(val_list)) / float(batch_size)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuXtg2lAPtMI"
      },
      "source": [
        "## Part 4 - Experimental evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJQFiiz5PtMJ"
      },
      "source": [
        "#### Metrics: history\n",
        "\n",
        "We show in the following part the results in term of metrics during the training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CCPhH_WPtMK"
      },
      "outputs": [],
      "source": [
        "def history_results(history, par1='loss', par2='val_loss', title='loss'):\n",
        "    \"\"\"\n",
        "    Plot the history of the the 2 metrics (par1, par2) during\n",
        "    the training (epochs)\n",
        "    \"\"\"\n",
        "    plt.plot(history.history[par1])\n",
        "    plt.plot(history.history[par2])\n",
        "    plt.title(title)\n",
        "    plt.ylabel(par1)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "# print(history)\n",
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/ProjectPhaseB/super_resolution_weights.h5'\n",
        "\n",
        "# Ensure the directory exists, create it if necessary\n",
        "directory = os.path.dirname(path)\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "\n",
        "# # Assuming 'model' is your trained model\n",
        "model.save_weights(path)\n",
        "print(f\"Model weights saved to '{path}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n9pVOM0Q-Yk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir(os.getcwd()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krpZfYHdPtMM"
      },
      "outputs": [],
      "source": [
        "history_results(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi7A5bQfPtMP"
      },
      "outputs": [],
      "source": [
        "history_results(history, 'psnr', 'val_psnr', 'psnr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsT4hYmKPtMT"
      },
      "outputs": [],
      "source": [
        "history_results(history, 'ssim', 'val_ssim', 'ssim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzSVg9ghPtMW"
      },
      "outputs": [],
      "source": [
        "history_results(history, 'mean_squared_error', 'val_mean_squared_error', 'means_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrzQkpErPtMY"
      },
      "source": [
        "#### Showing some visual results of Super-Resolution\n",
        "\n",
        "In testing mode, 128x128 pixels images are used and then the result it's compared with 256x256 pixels images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itDYwl3vPtMZ"
      },
      "outputs": [],
      "source": [
        "def show_pictures(img_idx, x_batch, y_batch):\n",
        "    \"\"\"\n",
        "    Function which shows 3 images:\n",
        "    - Ground truth: High Resolution image\n",
        "    - Low Resolution image\n",
        "    - Super Resolution image using our trained model\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(15,18))\n",
        "\n",
        "    ax1 = fig.add_subplot(1,3,1)\n",
        "    im = model(np.expand_dims(x_batch[img_idx],axis=0))\n",
        "    im = np.squeeze(im)\n",
        "    #ax1.imshow((abs(im) * 255).astype(np.uint8))\n",
        "    ax1.imshow(abs(im))\n",
        "    ax1.set_title('Super Resolution (from LR)')\n",
        "\n",
        "    ax2 = fig.add_subplot(1,3,2)\n",
        "    #ax2.imshow(x_batch[img_idx] * 255).astype(np.uint8))\n",
        "    ax2.imshow(x_batch[img_idx])\n",
        "    ax2.set_title('Low Resolution')\n",
        "\n",
        "    ax3 = fig.add_subplot(1,3,3)\n",
        "    #ax3.imshow((y_batch[img_idx] * 255).astype(np.uint8))\n",
        "    ax3.imshow(y_batch[img_idx])\n",
        "    ax3.set_title('Ground truth')\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLs68lUfPtMb"
      },
      "outputs": [],
      "source": [
        "# trying to visualize the results with some training images\n",
        "\n",
        "chunk_size=20\n",
        "\n",
        "x_chunk = []\n",
        "y_chunk = []\n",
        "\n",
        "ids_train_chunk = train_list[0:chunk_size]\n",
        "for i,ids in enumerate(ids_train_chunk):\n",
        "    img_y = read_image(ids)\n",
        "    img_x = image_preprocess(img_y)\n",
        "    x_chunk.append(np.array(img_x,np.float32)/255.)\n",
        "    y_chunk.append(np.array(img_y,np.float32)/255.)\n",
        "x_chunk = np.array(x_chunk)\n",
        "y_chunk = np.array(y_chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-UXvlHaPtMd"
      },
      "outputs": [],
      "source": [
        "x_chunk.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EythdVNHPtMf"
      },
      "outputs": [],
      "source": [
        "show_pictures(7, x_chunk, y_chunk)\n",
        "show_pictures(16, x_chunk, y_chunk)\n",
        "show_pictures(19, x_chunk, y_chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eVOKU8kPtMi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def read_image(img_path):\n",
        "    \"\"\"\n",
        "    Reads an image from a file path.\n",
        "    Converts from BGR to RGB format.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: Unable to read image at {img_path}\")\n",
        "        return None\n",
        "    b, g, r = cv2.split(img)   # cv2 reads BGR instead of canonical RGB\n",
        "    img = cv2.merge([r, g, b]) # Switching it to RGB\n",
        "    return img\n",
        "\n",
        "def get_image_paths(root_dir, size):\n",
        "    \"\"\"\n",
        "    Collects image paths from the directory and filters by size.\n",
        "    \"\"\"\n",
        "    image_paths = []\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for filename in filenames:\n",
        "            if size in filename:  # Assuming size (e.g., '64' or '256') is in the filename\n",
        "                image_paths.append(os.path.join(dirpath, filename))\n",
        "    return image_paths\n",
        "\n",
        "# Assuming image_preprocess is defined elsewhere\n",
        "\n",
        "# Get all 256x256 image paths for training\n",
        "train_root_dir = 'Linnaeus_5_bigger/train_256'\n",
        "train_size = '256'\n",
        "train_list = get_image_paths(train_root_dir, train_size)\n",
        "\n",
        "# Get all 128x128 image paths for testing\n",
        "test_root_dir = 'Linnaeus_5_bigger/test_128'\n",
        "test_size = '128'\n",
        "test_list = get_image_paths(test_root_dir, test_size)\n",
        "\n",
        "# Prepare training data\n",
        "x_train_chunk = []\n",
        "y_train_chunk = []\n",
        "train_chunk_size = 10  # Adjust the chunk size as needed\n",
        "ids_train_chunk = train_list[:train_chunk_size]\n",
        "\n",
        "for i, ids in enumerate(ids_train_chunk):\n",
        "    # Construct the path for the corresponding 256x256 image\n",
        "    ids_256 = ids.replace(train_size, train_size)\n",
        "    print(f\"Processing: 256x256 image at {ids_256}\")\n",
        "\n",
        "    # Check if the 256x256 image file exists\n",
        "    if not os.path.isfile(ids_256):\n",
        "        print(f\"256x256 image file does not exist: {ids_256}\")\n",
        "        continue\n",
        "\n",
        "    img_x = read_image(ids_256)     # x: 256x256 img\n",
        "    if img_x is None:\n",
        "        print(f\"Skipping image at {ids_256}\")\n",
        "        continue\n",
        "\n",
        "    img_x = image_preprocess(img_x, training_mode=False)\n",
        "\n",
        "    x_train_chunk.append(np.array(img_x, np.float32) / 255.)\n",
        "    y_train_chunk.append(np.array(img_x, np.float32) / 255.)  # Same image for both x and y for training\n",
        "\n",
        "x_train_chunk = np.array(x_train_chunk)\n",
        "y_train_chunk = np.array(y_train_chunk)\n",
        "\n",
        "print(f\"Processed {len(x_train_chunk)} training image pairs.\")\n",
        "\n",
        "# Prepare testing data\n",
        "x_test_chunk = []\n",
        "y_test_chunk = []\n",
        "test_chunk_size = 10  # Adjust the chunk size as needed\n",
        "ids_test_chunk = test_list[:test_chunk_size]\n",
        "\n",
        "for i, ids in enumerate(ids_test_chunk):\n",
        "    # Construct the path for the corresponding 128x128 image\n",
        "    ids_128 = ids.replace(test_size, test_size)\n",
        "    print(f\"Processing: 128x128 image at {ids_128}\")\n",
        "\n",
        "    # Check if the 128x128 image file exists\n",
        "    if not os.path.isfile(ids_128):\n",
        "        print(f\"128x128 image file does not exist: {ids_128}\")\n",
        "        continue\n",
        "\n",
        "    img_x = read_image(ids_128)     # x: 128x128 img\n",
        "    if img_x is None:\n",
        "        print(f\"Skipping image at {ids_128}\")\n",
        "        continue\n",
        "\n",
        "    img_x = image_preprocess(img_x, training_mode=False)\n",
        "\n",
        "    x_test_chunk.append(np.array(img_x, np.float32) / 255.)\n",
        "    y_test_chunk.append(np.array(img_x, np.float32) / 255.)  # Same image for both x and y for testing\n",
        "\n",
        "x_test_chunk = np.array(x_test_chunk)\n",
        "y_test_chunk = np.array(y_test_chunk)\n",
        "\n",
        "print(f\"Processed {len(x_test_chunk)} testing image pairs.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi-1vfOlPtMp"
      },
      "outputs": [],
      "source": [
        "x_chunk.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wlgu0t5ePtMs"
      },
      "outputs": [],
      "source": [
        "show_pictures(4, x_chunk, y_chunk)\n",
        "show_pictures(5, x_chunk, y_chunk)\n",
        "show_pictures(9, x_chunk, y_chunk)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}